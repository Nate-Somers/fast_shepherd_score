# shepherd_score/alignment_utils/fast_esp_combo_se3.py
# Fast GPU-accelerated ESP combo alignment.
# Combines shape overlap (using Triton kernel) with surface ESP comparison.

import torch
import torch.nn.functional as F
from typing import Tuple, Optional

from ..score.gaussian_overlap_triton import (
    overlap_score_grad_se3_batch,
    fused_adam_qt,
    fused_adam_qt_with_tangent_proj,
    _batch_self_overlap
)
from ..score.constants import COULOMB_SCALING, LAM_SCALING
from .fast_common import (
    check_gpu_available,
    legacy_seeds_torch,
    build_coarse_grid,
    quat_mul,
    apply_se3_transform,
    apply_so3_transform,
    quaternion_to_rotation_matrix
)


@torch.no_grad()
def _overlap_in_chunks_volumetric(A, B, q, t, *, alpha: float,
                                   N_real: torch.Tensor,
                                   M_real: torch.Tensor,
                                   NEED_GRAD: bool = True,
                                   BLOCK: int = 64):
    """Evaluate volumetric overlap kernel in chunks."""
    K = A.shape[0]
    N_real = N_real.to(torch.int32).contiguous()
    M_real = M_real.to(torch.int32).contiguous()

    out_V = torch.empty(K, device=A.device, dtype=A.dtype)
    out_dQ = torch.empty_like(q)
    out_dT = torch.empty_like(t)

    CHUNK = 65_535

    for start in range(0, K, CHUNK):
        end = min(start + CHUNK, K)

        V, dQ, dT = overlap_score_grad_se3_batch(
            A[start:end], B[start:end],
            q[start:end], t[start:end],
            alpha=alpha,
            N_real=N_real[start:end],
            M_real=M_real[start:end],
            NEED_GRAD=NEED_GRAD,
            BLOCK=BLOCK)

        out_V[start:end] = V
        out_dQ[start:end] = dQ
        out_dT[start:end] = dT

    return out_V, out_dQ, out_dT


def _self_overlap_chunks(P_pad, N_real, alpha):
    """Compute volumetric self-overlap in chunks."""
    K = P_pad.size(0)
    CHUNK = 65_535
    V_all = torch.empty(K, device=P_pad.device, dtype=P_pad.dtype)

    for s in range(0, K, CHUNK):
        e = min(s + CHUNK, K)
        V_all[s:e] = _batch_self_overlap(P_pad[s:e], N_real[s:e], alpha)

    return V_all


@torch.no_grad()
def _batch_esp_comparison(points_1: torch.Tensor,
                          centers_w_H_2: torch.Tensor,
                          partial_charges_2: torch.Tensor,
                          points_charges_1: torch.Tensor,
                          radii_2: torch.Tensor,
                          M_real_atoms: torch.Tensor,
                          N_real_surf: torch.Tensor,
                          probe_radius: float = 1.0,
                          lam: float = 0.001) -> torch.Tensor:
    """
    Batched ESP comparison on GPU.

    Computes the difference in ESP at surface points of molecule 1 for the ESP
    values generated by molecule 1 and molecule 2, with masking for overlapping
    volumes.

    Parameters
    ----------
    points_1 : torch.Tensor (B, N_surf, 3)
        Surface points of molecule 1
    centers_w_H_2 : torch.Tensor (B, M_atoms, 3)
        Atom coordinates (with H) of molecule 2
    partial_charges_2 : torch.Tensor (B, M_atoms)
        Partial charges of molecule 2
    points_charges_1 : torch.Tensor (B, N_surf)
        Pre-computed ESP at points_1 from molecule 1
    radii_2 : torch.Tensor (B, M_atoms)
        VdW radii of molecule 2 atoms
    probe_radius : float
        Probe radius for masking
    lam : float
        ESP weighting parameter

    Returns
    -------
    esp : torch.Tensor (B,)
        ESP comparison scores
    """
    lam_scaled = LAM_SCALING * lam

    # distances: (B, N_surf, M_atoms)
    distances = torch.cdist(points_1, centers_w_H_2)

    # mask: surface points outside molecule 2's volume
    # mask = (all distances >= radii + probe) -> 1.0, else 0.0
    BATCH, N_surf_pad, M_atoms_pad = distances.shape
    atom_mask = (
        torch.arange(M_atoms_pad, device=distances.device).view(1, 1, M_atoms_pad)
        < M_real_atoms.view(BATCH, 1, 1)
    )
    cond = distances >= (radii_2.unsqueeze(1) + probe_radius)
    cond = cond | (~atom_mask)  # padded atoms are non-blocking
    mask = cond.all(dim=2).float()

    surf_mask = (
        torch.arange(N_surf_pad, device=distances.device).view(1, N_surf_pad)
        < N_real_surf.view(BATCH, 1)
    ).float()
    mask = mask * surf_mask

    # ESP at surface points due to molecule 2's partial charges
    # Use reciprocal distances, clamp to avoid division by zero
    inv_distances = 1.0 / distances.clamp(min=1e-6)  # (B, N_surf, M_atoms)
    inv_distances = inv_distances * atom_mask.to(inv_distances.dtype)
    partial_charges_2 = partial_charges_2 * atom_mask[:, 0, :].to(partial_charges_2.dtype)
    esp_at_surf_1 = torch.einsum('bm,bnm->bn', partial_charges_2, inv_distances) * COULOMB_SCALING

    # ESP similarity
    diff_sq = (points_charges_1 - esp_at_surf_1) ** 2
    esp = (mask * torch.exp(-diff_sq / lam_scaled)).sum(dim=1)

    return esp


@torch.no_grad()
def _batch_esp_combo_score(
        centers_w_H_1: torch.Tensor,
        centers_w_H_2: torch.Tensor,
        centers_1: torch.Tensor,
        centers_2: torch.Tensor,
        points_1: torch.Tensor,
        points_2: torch.Tensor,
        partial_charges_1: torch.Tensor,
        partial_charges_2: torch.Tensor,
        point_charges_1: torch.Tensor,
        point_charges_2: torch.Tensor,
        radii_1: torch.Tensor,
        radii_2: torch.Tensor,
        alpha: float,
        lam: float,
        probe_radius: float,
        esp_weight: float,
        VAA: torch.Tensor,
        VBB: torch.Tensor,
        N_real_centers: torch.Tensor,
        M_real_centers: torch.Tensor,
        N_real_atoms_w_H_1: torch.Tensor,
        M_real_atoms_w_H_2: torch.Tensor,
        N_real_surf_1: torch.Tensor,
        M_real_surf_2: torch.Tensor) -> torch.Tensor:
    """
    Compute batched ESP combo score (shape + ESP similarity).

    Returns
    -------
    score : torch.Tensor (B,)
        Combined similarity scores
    """
    BATCH = centers_1.shape[0]
    N_surf = N_real_surf_1.to(dtype=centers_1.dtype)
    M_surf = M_real_surf_2.to(dtype=centers_1.dtype)

    # Shape similarity using volumetric kernel
    VAB, _, _ = _overlap_in_chunks_volumetric(
        centers_1, centers_2,
        torch.tensor([[1., 0., 0., 0.]], device=centers_1.device).expand(BATCH, 4),
        torch.zeros(BATCH, 3, device=centers_1.device),
        alpha=alpha,
        N_real=N_real_centers,
        M_real=M_real_centers,
        NEED_GRAD=False)

    volumetric_sim = VAB / (VAA + VBB - VAB)

    # ESP similarity
    esp_1 = _batch_esp_comparison(
        points_1, centers_w_H_2, partial_charges_2,
        point_charges_1, radii_2,
        M_real_atoms_w_H_2, N_real_surf_1,
        probe_radius, lam)
    esp_2 = _batch_esp_comparison(
        points_2, centers_w_H_1, partial_charges_1,
        point_charges_2, radii_1,
        N_real_atoms_w_H_1, M_real_surf_2,
        probe_radius, lam)

    electrostatic_sim = (esp_1 + esp_2) / (N_surf + M_surf)

    # Combined score
    score = esp_weight * electrostatic_sim + (1 - esp_weight) * volumetric_sim

    return score


def coarse_fine_esp_combo_align_many(
        centers_w_H_1: torch.Tensor,
        centers_w_H_2: torch.Tensor,
        centers_1: torch.Tensor,
        centers_2: torch.Tensor,
        points_1: torch.Tensor,
        points_2: torch.Tensor,
        partial_charges_1: torch.Tensor,
        partial_charges_2: torch.Tensor,
        point_charges_1: torch.Tensor,
        point_charges_2: torch.Tensor,
        radii_1: torch.Tensor,
        radii_2: torch.Tensor,
        VAA: torch.Tensor,
        VBB: torch.Tensor,
        *,
        alpha: float,
        lam: float = 0.001,
        probe_radius: float = 1.0,
        esp_weight: float = 0.5,
        trans_centers: Optional[torch.Tensor] = None,
        trans_centers_real: Optional[torch.Tensor] = None,
        num_repeats_per_trans: int = 10,
        topk: int = 30,
        steps_fine: int = 75,
        lr: float = 0.075,
        N_real_centers: Optional[torch.Tensor] = None,
        M_real_centers: Optional[torch.Tensor] = None,
        N_real_atoms_w_H_1: Optional[torch.Tensor] = None,
        M_real_atoms_w_H_2: Optional[torch.Tensor] = None,
        N_real_surf_1: Optional[torch.Tensor] = None,
        M_real_surf_2: Optional[torch.Tensor] = None,
        early_stop_patience: int = 5,
        early_stop_tol: float = 1e-5) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Vectorized ESP combo alignment over a batch of molecule pairs.

    Uses coarse-to-fine strategy with the combined shape + ESP scoring.

    Returns
    -------
    final_score : torch.Tensor (B,)
        Best combo scores
    q_best : torch.Tensor (B, 4)
        Best quaternions
    t_best : torch.Tensor (B, 3)
        Best translations
    """
    device = centers_1.device
    BATCH = centers_1.shape[0]
    N_pad_centers = centers_1.shape[1]
    M_pad_centers = centers_2.shape[1]
    N_pad_w_H = centers_w_H_1.shape[1]
    M_pad_w_H = centers_w_H_2.shape[1]
    N_surf = points_1.shape[1]
    M_surf = points_2.shape[1]

    if N_real_centers is None:
        N_real_centers = centers_1.new_full((BATCH,), N_pad_centers, dtype=torch.int32)
    if M_real_centers is None:
        M_real_centers = centers_2.new_full((BATCH,), M_pad_centers, dtype=torch.int32)
    if N_real_atoms_w_H_1 is None:
        N_real_atoms_w_H_1 = centers_w_H_1.new_full((BATCH,), N_pad_w_H, dtype=torch.int32)
    if M_real_atoms_w_H_2 is None:
        M_real_atoms_w_H_2 = centers_w_H_2.new_full((BATCH,), M_pad_w_H, dtype=torch.int32)
    if N_real_surf_1 is None:
        N_real_surf_1 = points_1.new_full((BATCH,), N_surf, dtype=torch.int32)
    if M_real_surf_2 is None:
        M_real_surf_2 = points_2.new_full((BATCH,), M_surf, dtype=torch.int32)

    # ------------------------------------------------------------------
    # 1) Build coarse grid of 500 poses
    # ------------------------------------------------------------------
    q_grid, t_grid = build_coarse_grid(
        points_1,
        points_2,
        N_real_surf_1,
        M_real_surf_2,
        num_seeds=50,
        trans_centers_batch=trans_centers,
        trans_centers_real=trans_centers_real,
        num_repeats_per_trans=num_repeats_per_trans,
    )
    G = q_grid.size(1)

    # ------------------------------------------------------------------
    # 2) Coarse evaluation
    # ------------------------------------------------------------------
    ORI_CHUNK = 5_000  # Smaller chunks due to more data per evaluation
    coarse_score = torch.empty(BATCH, G, device=device, dtype=centers_1.dtype)

    for o0 in range(0, G, ORI_CHUNK):
        o1 = min(o0 + ORI_CHUNK, G)
        g_len = o1 - o0

        # Expand all data for this chunk of orientations
        q_rep = q_grid[:, o0:o1].reshape(-1, 4).contiguous()
        t_rep = t_grid[:, o0:o1].reshape(-1, 3).contiguous()

        # Apply transforms to fit molecule data
        # Reshape: (B, g_len, ...) -> (B*g_len, ...)
        centers_w_H_2_exp = centers_w_H_2.unsqueeze(1).expand(-1, g_len, -1, -1).reshape(-1, M_pad_w_H, 3)
        centers_2_exp = centers_2.unsqueeze(1).expand(-1, g_len, -1, -1).reshape(-1, M_pad_centers, 3)
        points_2_exp = points_2.unsqueeze(1).expand(-1, g_len, -1, -1).reshape(-1, M_surf, 3)

        # Transform fit coordinates
        centers_w_H_2_t = apply_se3_transform(centers_w_H_2_exp, q_rep, t_rep)
        centers_2_t = apply_se3_transform(centers_2_exp, q_rep, t_rep)
        points_2_t = apply_se3_transform(points_2_exp, q_rep, t_rep)

        # Expand reference data
        centers_w_H_1_exp = centers_w_H_1.unsqueeze(1).expand(-1, g_len, -1, -1).reshape(-1, N_pad_w_H, 3)
        centers_1_exp = centers_1.unsqueeze(1).expand(-1, g_len, -1, -1).reshape(-1, N_pad_centers, 3)
        points_1_exp = points_1.unsqueeze(1).expand(-1, g_len, -1, -1).reshape(-1, N_surf, 3)
        partial_charges_1_exp = partial_charges_1.unsqueeze(1).expand(-1, g_len, -1).reshape(-1, N_pad_w_H)
        partial_charges_2_exp = partial_charges_2.unsqueeze(1).expand(-1, g_len, -1).reshape(-1, M_pad_w_H)
        point_charges_1_exp = point_charges_1.unsqueeze(1).expand(-1, g_len, -1).reshape(-1, N_surf)
        point_charges_2_exp = point_charges_2.unsqueeze(1).expand(-1, g_len, -1).reshape(-1, M_surf)
        radii_1_exp = radii_1.unsqueeze(1).expand(-1, g_len, -1).reshape(-1, N_pad_w_H)
        radii_2_exp = radii_2.unsqueeze(1).expand(-1, g_len, -1).reshape(-1, M_pad_w_H)
        VAA_exp = VAA.unsqueeze(1).expand(-1, g_len).reshape(-1)
        VBB_exp = VBB.unsqueeze(1).expand(-1, g_len).reshape(-1)
        N_real_exp = N_real_centers.repeat_interleave(g_len)
        M_real_exp = M_real_centers.repeat_interleave(g_len)
        N_atoms_exp = N_real_atoms_w_H_1.repeat_interleave(g_len)
        M_atoms_exp = M_real_atoms_w_H_2.repeat_interleave(g_len)
        N_surf_exp = N_real_surf_1.repeat_interleave(g_len)
        M_surf_exp = M_real_surf_2.repeat_interleave(g_len)

        # Compute combo scores
        scores_chunk = _batch_esp_combo_score(
            centers_w_H_1_exp, centers_w_H_2_t,
            centers_1_exp, centers_2_t,
            points_1_exp, points_2_t,
            partial_charges_1_exp, partial_charges_2_exp,
            point_charges_1_exp, point_charges_2_exp,
            radii_1_exp, radii_2_exp,
            alpha, lam, probe_radius, esp_weight,
            VAA_exp, VBB_exp, N_real_exp, M_real_exp,
            N_atoms_exp, M_atoms_exp, N_surf_exp, M_surf_exp)

        coarse_score[:, o0:o1] = scores_chunk.view(BATCH, g_len)

    # ------------------------------------------------------------------
    # 3) Select top-k orientations
    # ------------------------------------------------------------------
    best_idx = coarse_score.topk(k=topk, dim=1).indices
    q_best = torch.gather(q_grid, 1, best_idx.unsqueeze(-1).expand(-1, -1, 4)).clone()
    t_best = torch.gather(t_grid, 1, best_idx.unsqueeze(-1).expand(-1, -1, 3)).clone()

    # ------------------------------------------------------------------
    # 4) Fine optimization
    # ------------------------------------------------------------------
    # For ESP combo, we use the shape gradient for optimization but score with combo
    q_k = q_best.view(-1, 4)
    t_k = t_best.view(-1, 3)

    # Expand all data for topk
    centers_w_H_1_k = centers_w_H_1.unsqueeze(1).expand(-1, topk, -1, -1).reshape(-1, N_pad_w_H, 3)
    centers_w_H_2_k = centers_w_H_2.unsqueeze(1).expand(-1, topk, -1, -1).reshape(-1, M_pad_w_H, 3)
    centers_1_k = centers_1.unsqueeze(1).expand(-1, topk, -1, -1).reshape(-1, N_pad_centers, 3)
    centers_2_k = centers_2.unsqueeze(1).expand(-1, topk, -1, -1).reshape(-1, M_pad_centers, 3)
    points_1_k = points_1.unsqueeze(1).expand(-1, topk, -1, -1).reshape(-1, N_surf, 3)
    points_2_k = points_2.unsqueeze(1).expand(-1, topk, -1, -1).reshape(-1, M_surf, 3)
    partial_charges_1_k = partial_charges_1.unsqueeze(1).expand(-1, topk, -1).reshape(-1, N_pad_w_H)
    partial_charges_2_k = partial_charges_2.unsqueeze(1).expand(-1, topk, -1).reshape(-1, M_pad_w_H)
    point_charges_1_k = point_charges_1.unsqueeze(1).expand(-1, topk, -1).reshape(-1, N_surf)
    point_charges_2_k = point_charges_2.unsqueeze(1).expand(-1, topk, -1).reshape(-1, M_surf)
    radii_1_k = radii_1.unsqueeze(1).expand(-1, topk, -1).reshape(-1, N_pad_w_H)
    radii_2_k = radii_2.unsqueeze(1).expand(-1, topk, -1).reshape(-1, M_pad_w_H)

    N_k = N_real_centers.repeat_interleave(topk)
    M_k = M_real_centers.repeat_interleave(topk)
    N_atoms_k = N_real_atoms_w_H_1.repeat_interleave(topk)
    M_atoms_k = M_real_atoms_w_H_2.repeat_interleave(topk)
    N_surf_k = N_real_surf_1.repeat_interleave(topk)
    M_surf_k = M_real_surf_2.repeat_interleave(topk)
    VAA_k = VAA.repeat_interleave(topk)
    VBB_k = VBB.repeat_interleave(topk)
    VAA_plus_VBB = VAA_k + VBB_k

    # Adam state
    m_q = torch.zeros_like(q_k)
    v_q = torch.zeros_like(q_k)
    m_t = torch.zeros_like(t_k)
    v_t = torch.zeros_like(t_k)

    best_score = torch.full((len(q_k),), -float('inf'), device=device)
    best_q = q_k.clone()
    best_t = t_k.clone()

    prev_max_score = -float('inf')
    no_improve_count = 0

    for step in range(steps_fine):
        # Use shape gradients for optimization (ESP doesn't affect SE3 derivatives much)
        # Transform fit data
        centers_w_H_2_t = apply_se3_transform(centers_w_H_2_k, q_k, t_k)
        centers_2_t = apply_se3_transform(centers_2_k, q_k, t_k)
        points_2_t = apply_se3_transform(points_2_k, q_k, t_k)

        # Get shape gradients from kernel
        VAB, dQ, dT = _overlap_in_chunks_volumetric(
            centers_1_k, centers_2_k, q_k, t_k,
            alpha=alpha, N_real=N_k, M_real=M_k)

        # Compute full combo score for tracking
        score = _batch_esp_combo_score(
            centers_w_H_1_k, centers_w_H_2_t,
            centers_1_k, centers_2_t,
            points_1_k, points_2_t,
            partial_charges_1_k, partial_charges_2_k,
            point_charges_1_k, point_charges_2_k,
            radii_1_k, radii_2_k,
            alpha, lam, probe_radius, esp_weight,
            VAA_k, VBB_k, N_k, M_k,
            N_atoms_k, M_atoms_k, N_surf_k, M_surf_k)

        # Scale gradients for shape component
        denom = VAA_plus_VBB - VAB
        scale = VAA_plus_VBB / (denom * denom)

        # Track best
        better = score > best_score
        best_score = torch.where(better, score, best_score)
        mask_q = better.unsqueeze(1)
        best_q = torch.where(mask_q, q_k, best_q)
        best_t = torch.where(mask_q, t_k, best_t)

        # Early stopping check every 5 iterations to reduce GPUâ†’CPU sync overhead
        if step % 5 == 0:
            current_max = best_score.max().item()
            if current_max - prev_max_score < early_stop_tol:
                no_improve_count += 1
                if no_improve_count >= early_stop_patience:
                    break
            else:
                no_improve_count = 0
                prev_max_score = current_max

        # Fused Adam with tangent-space projection (avoids intermediate dQ_tan tensor)
        fused_adam_qt_with_tangent_proj(
            q_k, t_k,
            -dQ * scale.unsqueeze(1) * (1 - esp_weight),
            -dT * scale.unsqueeze(1) * (1 - esp_weight),
            m_q, v_q, m_t, v_t, lr)

    # ------------------------------------------------------------------
    # 5) Gather final results
    # ------------------------------------------------------------------
    final_score = best_score.view(BATCH, topk)
    best = final_score.argmax(dim=1)
    sel = best + torch.arange(BATCH, device=device) * topk

    return (final_score.flatten()[sel],
            best_q.view(BATCH, topk, 4)[torch.arange(BATCH), best],
            best_t.view(BATCH, topk, 3)[torch.arange(BATCH), best])


def fast_optimize_esp_combo_score_overlay(
        ref_centers_w_H: torch.Tensor,
        fit_centers_w_H: torch.Tensor,
        ref_centers: torch.Tensor,
        fit_centers: torch.Tensor,
        ref_points: torch.Tensor,
        fit_points: torch.Tensor,
        ref_partial_charges: torch.Tensor,
        fit_partial_charges: torch.Tensor,
        ref_surf_esp: torch.Tensor,
        fit_surf_esp: torch.Tensor,
        ref_radii: torch.Tensor,
        fit_radii: torch.Tensor,
        alpha: float,
        lam: float = 0.001,
        probe_radius: float = 1.0,
        esp_weight: float = 0.5,
        num_repeats: int = 50,
        trans_centers: Optional[torch.Tensor] = None,
        num_repeats_per_trans: int = 10,
        topk: int = 30,
        steps_fine: int = 75,
        lr: float = 0.075,
        **kwargs) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Fast GPU-accelerated ESP combo alignment.

    Drop-in replacement for optimize_esp_combo_score_overlay.

    Returns
    -------
    aligned_points : torch.Tensor (M, 3)
        Transformed fit surface points
    SE3_transform : torch.Tensor (4, 4)
        Best SE(3) transformation matrix
    score : torch.Tensor scalar
        Best combo score
    """
    if not check_gpu_available():
        from ..alignment import optimize_esp_combo_score_overlay
        return optimize_esp_combo_score_overlay(
            ref_centers_w_H, fit_centers_w_H,
            ref_centers, fit_centers,
            ref_points, fit_points,
            ref_partial_charges, fit_partial_charges,
            ref_surf_esp, fit_surf_esp,
            ref_radii, fit_radii,
            alpha, lam, probe_radius, esp_weight,
            num_repeats,
            trans_centers=trans_centers,
            **kwargs)

    device = torch.device('cuda')

    # Move to GPU and add batch dimension
    ref_centers_w_H_gpu = ref_centers_w_H.to(device, dtype=torch.float32).unsqueeze(0)
    fit_centers_w_H_gpu = fit_centers_w_H.to(device, dtype=torch.float32).unsqueeze(0)
    ref_centers_gpu = ref_centers.to(device, dtype=torch.float32).unsqueeze(0)
    fit_centers_gpu = fit_centers.to(device, dtype=torch.float32).unsqueeze(0)
    ref_points_gpu = ref_points.to(device, dtype=torch.float32).unsqueeze(0)
    fit_points_gpu = fit_points.to(device, dtype=torch.float32).unsqueeze(0)
    ref_partial_gpu = ref_partial_charges.to(device, dtype=torch.float32).unsqueeze(0)
    fit_partial_gpu = fit_partial_charges.to(device, dtype=torch.float32).unsqueeze(0)
    ref_esp_gpu = ref_surf_esp.to(device, dtype=torch.float32).unsqueeze(0)
    fit_esp_gpu = fit_surf_esp.to(device, dtype=torch.float32).unsqueeze(0)
    ref_radii_gpu = ref_radii.to(device, dtype=torch.float32).unsqueeze(0)
    fit_radii_gpu = fit_radii.to(device, dtype=torch.float32).unsqueeze(0)

    trans_centers_batch = None
    trans_centers_real = None
    if trans_centers is not None:
        tc = trans_centers.to(device, dtype=torch.float32)
        trans_centers_batch = tc.unsqueeze(0)
        trans_centers_real = torch.tensor([tc.shape[0]], device=device, dtype=torch.int32)

    aligned_batch, q_best, t_best, score = fast_optimize_esp_combo_score_overlay_batch(
        ref_centers_w_H_gpu, fit_centers_w_H_gpu,
        ref_centers_gpu, fit_centers_gpu,
        ref_points_gpu, fit_points_gpu,
        ref_partial_gpu, fit_partial_gpu,
        ref_esp_gpu, fit_esp_gpu,
        ref_radii_gpu, fit_radii_gpu,
        alpha,
        lam=lam,
        probe_radius=probe_radius,
        esp_weight=esp_weight,
        N_real_atoms_w_H_1=torch.tensor([ref_centers_w_H.shape[0]], device=device, dtype=torch.int32),
        M_real_atoms_w_H_2=torch.tensor([fit_centers_w_H.shape[0]], device=device, dtype=torch.int32),
        N_real_centers=torch.tensor([ref_centers.shape[0]], device=device, dtype=torch.int32),
        M_real_centers=torch.tensor([fit_centers.shape[0]], device=device, dtype=torch.int32),
        N_real_surf_1=torch.tensor([ref_points.shape[0]], device=device, dtype=torch.int32),
        M_real_surf_2=torch.tensor([fit_points.shape[0]], device=device, dtype=torch.int32),
        trans_centers_batch=trans_centers_batch,
        trans_centers_real=trans_centers_real,
        num_repeats_per_trans=num_repeats_per_trans,
        topk=topk,
        steps_fine=steps_fine,
        lr=lr,
    )
    aligned = aligned_batch[0]

    # Build SE(3) matrix
    R = quaternion_to_rotation_matrix(q_best[0])
    SE3 = torch.eye(4, device=device)
    SE3[:3, :3] = R
    SE3[:3, 3] = t_best[0]

    return aligned.cpu(), SE3.cpu(), score[0].cpu()


def fast_optimize_esp_combo_score_overlay_batch(
        ref_centers_w_H_batch: torch.Tensor,
        fit_centers_w_H_batch: torch.Tensor,
        ref_centers_batch: torch.Tensor,
        fit_centers_batch: torch.Tensor,
        ref_points_batch: torch.Tensor,
        fit_points_batch: torch.Tensor,
        ref_partial_charges_batch: torch.Tensor,
        fit_partial_charges_batch: torch.Tensor,
        ref_surf_esp_batch: torch.Tensor,
        fit_surf_esp_batch: torch.Tensor,
        ref_radii_batch: torch.Tensor,
        fit_radii_batch: torch.Tensor,
        alpha: float,
        *,
        lam: float = 0.001,
        probe_radius: float = 1.0,
        esp_weight: float = 0.5,
        N_real_atoms_w_H_1: Optional[torch.Tensor] = None,
        M_real_atoms_w_H_2: Optional[torch.Tensor] = None,
        N_real_centers: Optional[torch.Tensor] = None,
        M_real_centers: Optional[torch.Tensor] = None,
        N_real_surf_1: Optional[torch.Tensor] = None,
        M_real_surf_2: Optional[torch.Tensor] = None,
        trans_centers_batch: Optional[torch.Tensor] = None,
        trans_centers_real: Optional[torch.Tensor] = None,
        num_repeats_per_trans: int = 10,
        topk: int = 30,
        steps_fine: int = 75,
        lr: float = 0.075) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Fast GPU-accelerated batch ESP-combo alignment with padding-safe masks.

    Returns
    -------
    aligned_fit_points : torch.Tensor (B, M_surf_pad, 3)
    q_best : torch.Tensor (B, 4)
    t_best : torch.Tensor (B, 3)
    scores : torch.Tensor (B,)
    """
    device = ref_centers_batch.device
    BATCH = ref_centers_batch.shape[0]

    if N_real_centers is None:
        N_real_centers = ref_centers_batch.new_full(
            (BATCH,), ref_centers_batch.shape[1], dtype=torch.int32
        )
    if M_real_centers is None:
        M_real_centers = fit_centers_batch.new_full(
            (BATCH,), fit_centers_batch.shape[1], dtype=torch.int32
        )
    if N_real_atoms_w_H_1 is None:
        N_real_atoms_w_H_1 = ref_centers_w_H_batch.new_full(
            (BATCH,), ref_centers_w_H_batch.shape[1], dtype=torch.int32
        )
    if M_real_atoms_w_H_2 is None:
        M_real_atoms_w_H_2 = fit_centers_w_H_batch.new_full(
            (BATCH,), fit_centers_w_H_batch.shape[1], dtype=torch.int32
        )
    if N_real_surf_1 is None:
        N_real_surf_1 = ref_points_batch.new_full(
            (BATCH,), ref_points_batch.shape[1], dtype=torch.int32
        )
    if M_real_surf_2 is None:
        M_real_surf_2 = fit_points_batch.new_full(
            (BATCH,), fit_points_batch.shape[1], dtype=torch.int32
        )

    VAA = _self_overlap_chunks(ref_centers_batch, N_real_centers, alpha)
    VBB = _self_overlap_chunks(fit_centers_batch, M_real_centers, alpha)

    scores, q_best, t_best = coarse_fine_esp_combo_align_many(
        ref_centers_w_H_batch, fit_centers_w_H_batch,
        ref_centers_batch, fit_centers_batch,
        ref_points_batch, fit_points_batch,
        ref_partial_charges_batch, fit_partial_charges_batch,
        ref_surf_esp_batch, fit_surf_esp_batch,
        ref_radii_batch, fit_radii_batch,
        VAA, VBB,
        alpha=alpha,
        lam=lam,
        probe_radius=probe_radius,
        esp_weight=esp_weight,
        trans_centers=trans_centers_batch,
        trans_centers_real=trans_centers_real,
        num_repeats_per_trans=num_repeats_per_trans,
        topk=topk,
        steps_fine=steps_fine,
        lr=lr,
        N_real_centers=N_real_centers,
        M_real_centers=M_real_centers,
        N_real_atoms_w_H_1=N_real_atoms_w_H_1,
        M_real_atoms_w_H_2=M_real_atoms_w_H_2,
        N_real_surf_1=N_real_surf_1,
        M_real_surf_2=M_real_surf_2,
    )

    aligned_fit_points = apply_se3_transform(fit_points_batch, q_best, t_best)
    return aligned_fit_points, q_best, t_best, scores
